{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9354670,"sourceType":"datasetVersion","datasetId":5670827}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-19T16:38:14.492533Z","iopub.execute_input":"2024-09-19T16:38:14.493085Z","iopub.status.idle":"2024-09-19T16:38:14.503279Z","shell.execute_reply.started":"2024-09-19T16:38:14.493030Z","shell.execute_reply":"2024-09-19T16:38:14.501936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/phishing-url-detection/out.csv\")\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)          #Kullandığım veri seti zararlı \n#ve zararsız label değerlerine göre sıralandığı için ve boyutunun büyük olması nedeniyle\n#sınırlamam gerekmesiyle bu yöntemi kullanrak satırları ayrıca karıştırdım.\ndf = df.head(30000)       #İlk 30000 satırı dataframe'e ekledim.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:38:17.977381Z","iopub.execute_input":"2024-09-19T16:38:17.977938Z","iopub.status.idle":"2024-09-19T16:39:12.886027Z","shell.execute_reply.started":"2024-09-19T16:38:17.977880Z","shell.execute_reply":"2024-09-19T16:39:12.884824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()       #Veri seti hakkında bilgileri yazdırdım.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:39:19.242807Z","iopub.execute_input":"2024-09-19T16:39:19.243270Z","iopub.status.idle":"2024-09-19T16:39:19.315914Z","shell.execute_reply.started":"2024-09-19T16:39:19.243224Z","shell.execute_reply":"2024-09-19T16:39:19.314675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()       #İlk 5 satır veriyi inceledim. Hem zararlı hem de zararsız URL'leri de içeriyor.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:39:21.675381Z","iopub.execute_input":"2024-09-19T16:39:21.675848Z","iopub.status.idle":"2024-09-19T16:39:21.700612Z","shell.execute_reply.started":"2024-09-19T16:39:21.675797Z","shell.execute_reply":"2024-09-19T16:39:21.699095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()       #Hücrelerde boş kısım var mı kontrol ettim. Yok gibi görünüyordu ancak fit fonksiyonu\n#çalışınca yine de hata veriyordu.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:39:24.118845Z","iopub.execute_input":"2024-09-19T16:39:24.119469Z","iopub.status.idle":"2024-09-19T16:39:24.182416Z","shell.execute_reply.started":"2024-09-19T16:39:24.119403Z","shell.execute_reply":"2024-09-19T16:39:24.180995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()       #Sütunlara göre Null veri sayılarını yazan bu fonksiyonları çalıştırdım ve\n#hois_data ve domain_age_days adlı sütunlarda Null değvrler olduğunu tespit ettim.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:39:28.909740Z","iopub.execute_input":"2024-09-19T16:39:28.910272Z","iopub.status.idle":"2024-09-19T16:39:28.926624Z","shell.execute_reply.started":"2024-09-19T16:39:28.910221Z","shell.execute_reply":"2024-09-19T16:39:28.924921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()       #Ayrıca label adlı sütundaki değerlerin sayılarının istenmeyecek\n#kadar çok yakın olduğunu gördüm.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:39:31.242712Z","iopub.execute_input":"2024-09-19T16:39:31.243184Z","iopub.status.idle":"2024-09-19T16:39:31.276765Z","shell.execute_reply.started":"2024-09-19T16:39:31.243135Z","shell.execute_reply":"2024-09-19T16:39:31.275531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=['domain_age_days', 'whois_data'])       #Bu iki sütunu tablodan sildim.\ndf.isnull().sum()       #Tekrar Null içeren sütunları görmek için bu fonksiyonu çalıştırdım ve\n#Null öğe kalmamıştı.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T17:03:30.115395Z","iopub.execute_input":"2024-09-19T17:03:30.116728Z","iopub.status.idle":"2024-09-19T17:03:30.190896Z","shell.execute_reply.started":"2024-09-19T17:03:30.116663Z","shell.execute_reply":"2024-09-19T17:03:30.189531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()       #Tekrar label sütununun veri değerleri sayılarının uzaklığı gerçeğe daha\n#yakın sonuç alabilmemiz için yeterli görünüyor. Buraya kadar eda işlemleri tamamlanmış oldu.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T17:03:34.438090Z","iopub.execute_input":"2024-09-19T17:03:34.438583Z","iopub.status.idle":"2024-09-19T17:03:34.453961Z","shell.execute_reply.started":"2024-09-19T17:03:34.438536Z","shell.execute_reply":"2024-09-19T17:03:34.452407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='label', data=df)\nplt.title('Sınıf Dağılımı')\nplt.xlabel('Sınıf')\nplt.ylabel('Sayı')\nplt.xticks(ticks=[0, 1], labels=['Phishing', 'Benign'])  # Etiketleri güncelle\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T18:43:44.719324Z","iopub.execute_input":"2024-09-19T18:43:44.725845Z","iopub.status.idle":"2024-09-19T18:43:45.192633Z","shell.execute_reply.started":"2024-09-19T18:43:44.725729Z","shell.execute_reply":"2024-09-19T18:43:45.191158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.barplot(x='source', y='label', data=df, estimator=lambda x: len(x) / len(df) * 100)  # Yüzde olarak gösterim\nplt.title('Kaynaklara Göre Sınıf Dağılımı')\nplt.xlabel('Kaynak')\nplt.ylabel('Yüzde')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T18:44:09.428965Z","iopub.execute_input":"2024-09-19T18:44:09.429461Z","iopub.status.idle":"2024-09-19T18:44:10.009728Z","shell.execute_reply.started":"2024-09-19T18:44:09.429412Z","shell.execute_reply":"2024-09-19T18:44:10.008212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimli Öğrenme Modelleri\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n#Buraya kadar denetimli öğrenme modellerini ve çeşitli sınıflandırma ve etiketleme modüllerini import ettim\n\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['label'])\ndf['source'] = label_encoder.fit_transform(df['source'])\n#Bazı sütunlarım (label ve source) kategorik veriler içeriyordu, bunları Label encoder modülü ile etiketledim\n\ndef denetimli_modeller(models):\n    #Denetmli modelleri tek tek veri seti üzerinde deneyip accuracy scoure değerine göre en kullanışlı olanı\n    #belirleyecek bir fonksiyon yazdım.\n    X = df.drop(columns=['url', 'label', 'whois_data'])       #Denetimli öğrenmede hedef çıktımız label sütununda \n    #bulunduğu için label sütunu, url sütunundaki veriler ise hem işe yaramaz hem de karmaşık olduğundan \n    #bu iki sütunu drop ediyoruz. Kalan sütunları da kaynak dataframe'imiz olacak X'e atıyoruz.\n    y = df['label']       #Hedefimizdeki sütunu ise y adlı dataframe'e atıyoruz karşılaştırmak için.\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    #Burada ise eğitim ve test kümelerimizi oluşturuyoruz. Verilvrimizin %30'unu teste ayırıyor ve\n    #daha etkili bir test oluşturmak için 42 parametresine göre verileri karıştırıyoruz.\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    #StandartScaler modülü ile veri normalizasyonu (güzelleme) yapıyoruz.\n    \n\n    best_model_name = None\n    best_accuracy = 0\n    \n    for name, model in models.items():\n        model.fit(X_train_scaled, y_train)       #fit fonksiyonu ile makinemize eğitilecek kümeleri veriyoruz\n        #ve eğitmeye başlıyoruz sırayla model adlı dizide bulunan modellerle.\n        y_pred = model.predict(X_test_scaled)       #Sonucu normalize edilmiş test verimiz ile karşılaştırıyoruz.\n        \n        accuracy = accuracy_score(y_test, y_pred)       #Modellerin doğruluk değerleri değişkene atanır.\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        \n        print(f\"Model: {name}\")       #Sırayla her model karışıklık matrisi ile çıktıya yazılır.\n        print(classification_report(y_test, y_pred))\n        print(confusion_matrix(y_test, y_pred))\n        \n        \"\"\"Cross Validation işlemi, bu kısmı tam olarak çalışır hale getiremedim :')\n        scores = cross_val_score(best_model_name, X_scaled, y, cv=5, scoring='accuracy')\n        mean_accuracy = np.mean(scores)\n        print(f\"Model: {model_name}, Cross-Validation Mean Accuracy: {mean_accuracy:}\")\"\"\"\n        \n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_model_name = name\n        #Bu if bloğu içinde ise en yüksek doğruluk değerine sahip model belirlenir.\n    \n    return best_model_name, best_accuracy       #en yüksek doğruluk değerine sahip model ve değeri \n    #return edilir.\n\n\nmodels = {\n    'Logistic Regression': LogisticRegression(max_iter=200),\n    'SVM': SVC(kernel='linear'),\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n    '.Naive Bayes': GaussianNB(),\n    'Neural Network': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n}       #Denetimli öğrenme modellerini tutan küme, fonksiyona göndermek üzere.\n\nbest_model_name, best_accuracy = denetimli_modeller(models)       #Fonksiyon çalıştırılır.\nprint(f\"\\nBest Model: {best_model_name} with Accuracy: {best_accuracy:}\")\n#en iyi sonuç veren model ve doğruluk değeri yazdırılır.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T19:19:03.702468Z","iopub.execute_input":"2024-09-19T19:19:03.703440Z","iopub.status.idle":"2024-09-19T19:19:11.885142Z","shell.execute_reply.started":"2024-09-19T19:19:03.703378Z","shell.execute_reply":"2024-09-19T19:19:11.883584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimsiz Öğrenme Modelleri\n\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n#Kullanacağımız modüllerin import edilmesi\n\nlabel_encoder = LabelEncoder()\ndf['source'] = label_encoder.fit_transform(df['source'])\n#Kategorik veriler içeren sütun (source) encode edilmesi\n\nX = df.drop(columns=['url', 'label', 'whois_data'])       #Kullanmayacağımız sütunların dataframe'den çıkarılması\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n#Verilerin normalize edilmesi\n\nmodels = {\n    'KMeans': KMeans(n_clusters=2, random_state=42, n_init = 10),\n    'Agglomerative Clustering': AgglomerativeClustering(n_clusters=2),\n    'DBSCAN': DBSCAN(eps=5, min_samples=5)\n}       #Fonksiyona gönderilmek üzere denetimsiz öğrenme modellerinin kümede tutulması\n\ndef denetimsiz_modeller(models, X_scaled):\n    best_model_name = None\n    best_score = -1\n    \n    #Bu döngü ile modellerin fit_predict mi yoksa fit fonksiyonunu mu kullandığının tespitine göre öğrenme\n    #işlemi başlatılır.\n    for name, model in models.items():\n        if hasattr(model, 'fit_predict'):\n            labels = model.fit_predict(X_scaled)\n        else:\n            model.fit(X_scaled)\n            labels = model.labels_\n        \n        # Silhouette score hesaplama, denetimli öğrenmedeki gibi doğruluk oranının karşılığı olarak açıklanıyor\n        if len(set(labels)) > 1:  # Tek bir küme olursa silhouette score hesaplanamayacağından bunun kontrolü yapılıyor.\n            score = silhouette_score(X_scaled, labels)\n            print(f\"Model: {name}, Silhouette Score: {score:.4f}\")\n        \n            # En iyi sonuca göre en iyi denetimsiz öğrenme modelinin belirlenmesi ve en son da return edilmesi\n            if score > best_score:\n                best_score = score\n                best_model_name = name\n    \n    return best_model_name, best_score\n\n# En iyi modeli bulma\nbest_model_name, best_score = denetimsiz_modeller(models, X_scaled)       #Denetimsiz modeller fonksiyonunu çalıştırmaya yarar.\nprint(f\"Best Model: {best_model_name} with Silhouette Score: {best_score:.4f}\")\n#Belirlenen en iyi denetimsiz eğitim modeli ve silhouette değeri yazılır.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T19:01:55.108682Z","iopub.execute_input":"2024-09-19T19:01:55.109307Z","iopub.status.idle":"2024-09-19T19:03:19.255496Z","shell.execute_reply.started":"2024-09-19T19:01:55.109255Z","shell.execute_reply":"2024-09-19T19:03:19.254136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Son olarak şu kazanım; DBSCAN modelinde eps değerini arttırdıkça silhouette\n#değerinin de arttırğını gördüm.","metadata":{},"execution_count":null,"outputs":[]}]}